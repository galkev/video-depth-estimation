{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pathmagic\n",
    "from tools.project import proj_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-21 21:03:05,695] [<ipython-input-2-c2b49e3057b8>:3] DEBUG: test\n",
      "[2019-03-21 21:03:05,696] [<ipython-input-2-c2b49e3057b8>:4] INFO: hello\n"
     ]
    }
   ],
   "source": [
    "from tools.logger import logger\n",
    "\n",
    "logger.debug(\"test\")\n",
    "logger.info(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/miniconda2/envs/torch/lib/python3.6/site-packages/torch/cuda/__init__.py:118: UserWarning: \n",
      "    Found GPU0 GeForce GTX 660M which is of cuda capability 3.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability that we support is 3.5.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 224, 224])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda:0\"\n",
    "\n",
    "fs_size = 2\n",
    "batch_size = 1\n",
    "\n",
    "x = torch.rand(batch_size, fs_size, 3, 224, 224).to(device)\n",
    "\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from net import DDFFNetRNN, DDFFNet\n",
    "\n",
    "#net = DDFFNetRNNEncCat(focal_stack_size=fs_size, lstm_dim=512).to(device)\n",
    "#net = DDFFNetRNN(fs_size, 512, rnn_type=\"lstm\", rnn_num_layers=2, rnn_embedding=\"fc\", \n",
    "#                 ccx_reduce_mode=\"ccx_conv\").to(device)\n",
    "#net = DDFFNet(focal_stack_size=2, use_scoring=False, use_inter_scoring=True).to(device)\n",
    "net = DDFFNet(focal_stack_size=2, scoring_mode=\"inter/ccx_conv\", use_ccx=[False]*5).to(device)\n",
    "\n",
    "out = net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 224, 224])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import torch\\nfrom torch import nn\\n\\nlstm_in = 10\\nlstm_out = 20\\nlstm_layers = 1\\nbatch_size = 3\\nseq_len = 1\\n\\nlstm = nn.LSTM(lstm_in, lstm_out, num_layers=lstm_layers, bias=True, bidirectional=False)\\n\\nx = torch.rand(seq_len, batch_size, lstm_in)\\n\\nhn = torch.rand(lstm_layers, batch_size, lstm_out)\\ncn = torch.rand(lstm_layers, batch_size, lstm_out)\\n\\nout, (hn, cn) = lstm(x, (hn, cn))'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import torch\n",
    "from torch import nn\n",
    "\n",
    "lstm_in = 10\n",
    "lstm_out = 20\n",
    "lstm_layers = 1\n",
    "batch_size = 3\n",
    "seq_len = 1\n",
    "\n",
    "lstm = nn.LSTM(lstm_in, lstm_out, num_layers=lstm_layers, bias=True, bidirectional=False)\n",
    "\n",
    "x = torch.rand(seq_len, batch_size, lstm_in)\n",
    "\n",
    "hn = torch.rand(lstm_layers, batch_size, lstm_out)\n",
    "cn = torch.rand(lstm_layers, batch_size, lstm_out)\n",
    "\n",
    "out, (hn, cn) = lstm(x, (hn, cn))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(block)\\nprint(blocks[0])\\nprint(blocks[1])\\nprint(blocks[2])\\nprint(blocks[3])\\nprint(block_cat)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import torch\n",
    "from net.ddff_net_lstm import FourDirLSTM\n",
    "\n",
    "#a = torch.rand(18)\n",
    "\n",
    "block_size = 32\n",
    "\n",
    "a = torch.stack([\n",
    "    torch.arange(block_size * (2* block_size)), \n",
    "    torch.arange(block_size * (2* block_size), 2 * block_size * (2* block_size))]).float()\n",
    "batch_size = a.size(0)\n",
    "\n",
    "lstm = FourDirLSTM(block_size, batch_size)\n",
    "\n",
    "out = lstm(a)\n",
    "\n",
    "print(out.size())\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "print(a.size())\n",
    "\n",
    "block = a.view(batch_size, block_size, 2 * block_size)\n",
    "\n",
    "rev_idx = torch.arange(block_size-1, -1, -1)\n",
    "\n",
    "blocks = [None] * 4\n",
    "\n",
    "blocks[1] = block[:, :, :block_size].permute(1, 0, 2)\n",
    "blocks[0] = blocks[1].permute(2, 1, 0)\n",
    "blocks[3] = block[:, :, block_size:].index_select(1, rev_idx).index_select(2, rev_idx).permute(1, 0, 2)\n",
    "blocks[2] = blocks[3].permute(2, 1, 0)\n",
    "\n",
    "# lstm start\n",
    "lstms = [torch.nn.LSTM(block_size, block_size) for _ in range(4)]\n",
    "hidden = [(\n",
    "    torch.zeros([1, batch_size, block_size]),\n",
    "    torch.zeros([1, batch_size, block_size]))\n",
    "    for _ in range(4)]\n",
    "\n",
    "blocks_out = [None] * 4\n",
    "\n",
    "for i, lstm in enumerate(lstms):\n",
    "    out, hidden[i] = lstm(blocks[i], hidden[i])\n",
    "    blocks_out[i] = out[-1]\n",
    "    \n",
    "    #print(((blocks_out[i] - hidden[i][0])**2).sum())\n",
    "# lstm end\n",
    "\n",
    "block_cat = torch.cat(blocks_out, dim=1)\n",
    "\n",
    "print(block_cat.size())\"\"\"\n",
    "\n",
    "\"\"\"block_cat = torch.cat([\n",
    "    block_a.permute(1, 0, 2).view(batch_size, -1),\n",
    "    block_b.permute(1, 0, 2).view(batch_size, -1),\n",
    "    block_c.permute(1, 0, 2).view(batch_size, -1),\n",
    "    block_d.permute(1, 0, 2).view(batch_size, -1)\n",
    "])\n",
    "\n",
    "#print(a.size())\n",
    "print(block.size())\n",
    "print(blocks[0].size())\n",
    "print(blocks[1].size())\n",
    "print(blocks[2].size())\n",
    "print(blocks[3].size())\n",
    "print(block_cat.size())\"\"\"\n",
    "\n",
    "\"\"\"print(block)\n",
    "print(blocks[0])\n",
    "print(blocks[1])\n",
    "print(blocks[2])\n",
    "print(blocks[3])\n",
    "print(block_cat)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
