{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pathmagic\n",
    "from tools.project import proj_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.multiprocessing.set_sharing_strategy('file_system')\n",
      "WARNING: model_gen lambda has no input param for num_in_channels\n",
      "Output mode: last\n",
      "include_all_coc False\n",
      "Val losses [Masked(MSELoss()), Masked(AccuracyLoss())]\n",
      "Train loss Masked(MSELoss())\n",
      "test\n",
      "Dataset type: test\n",
      "Test mode\n",
      "\n",
      "Data dirs ['../../../datasets/s7_real_mp4/test/seq0', '../../../datasets/s7_real_mp4/test/seq1', '../../../datasets/s7_real_mp4/test/seq2']\n",
      "Ext None\n",
      "Multi ramp\n",
      "Ramps in dataset 1\n",
      "Data class <class 'data.video_depth_focus_data.VideoDepthFocusDataMp4'>\n",
      "Using stats: ../../../datasets/s7_real_mp4/stats_total.json\n",
      "Data Stats {'focus_min': 0.1, 'focus_max': 0.5, 'frames': {'depth': {'min': 0, 'max': 1.5}}}\n",
      "Using hardcoded min depth 0.03!!!\n",
      "depth_normalize: Normalize(0.03, 1.5, clamp_max=False)\n",
      "coc_normalize: None\n",
      "signed_coc_normalize: None\n",
      "Latest epoch = 10\n",
      "Type: <class 'dict'>\n",
      "Error loading optimizer state dict -> OK since in test mode\n",
      "16:54:30 Loaded checkpoint\n",
      "16:54:30 [Epoch 10] TRAIN train_loss: 2.1965470\n",
      "16:54:30 [Epoch 10] VAL   train_loss: 1.5283622 mse: 1.5283622 acc: 46.82%\n",
      "16:54:30 TrainSetupDepth(\n",
      "model_id: 815\n",
      "model_desc: recur_ae_dummy_testset\n",
      "device: cuda\n",
      "model: PadCropModule(\n",
      "  (model): RecurrentAE(\n",
      "    (encoder): RecurrentAEEncoder(\n",
      "      (blocks): Sequential(\n",
      "        (0): EncoderBlock(\n",
      "          (layer1): Sequential(\n",
      "            (0): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(2, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (layer2): Sequential(\n",
      "            (0): Conv2d(4, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(2, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (layer3): Sequential(\n",
      "            (0): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(2, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): EncoderBlock(\n",
      "          (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (layer1): Sequential(\n",
      "            (0): Conv2d(2, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(3, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (layer2): Sequential(\n",
      "            (0): Conv2d(6, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(3, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (layer3): Sequential(\n",
      "            (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(3, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (2): EncoderBlock(\n",
      "          (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (layer1): Sequential(\n",
      "            (0): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(4, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (layer2): Sequential(\n",
      "            (0): Conv2d(8, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(4, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (layer3): Sequential(\n",
      "            (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(4, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (3): EncoderBlock(\n",
      "          (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (layer1): Sequential(\n",
      "            (0): Conv2d(4, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(5, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (layer2): Sequential(\n",
      "            (0): Conv2d(10, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(5, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (layer3): Sequential(\n",
      "            (0): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(5, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (4): EncoderBlock(\n",
      "          (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (layer1): Sequential(\n",
      "            (0): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(5, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (layer2): Sequential(\n",
      "            (0): Conv2d(10, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(5, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (layer3): Sequential(\n",
      "            (0): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(5, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): RecurrentAEDecoder(\n",
      "      (decoder_blocks): Sequential(\n",
      "        (0): DecoderBlock(\n",
      "          (up): ConvTranspose2d(5, 5, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(10, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(4, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(4, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): DecoderBlock(\n",
      "          (up): ConvTranspose2d(4, 4, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(3, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(3, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): DecoderBlock(\n",
      "          (up): ConvTranspose2d(3, 3, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(6, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(2, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(2, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): DecoderBlock(\n",
      "          (up): ConvTranspose2d(2, 2, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "          (layers): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(4, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(1, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "trainer: Trainer\n",
      "model_loader: ModelLoader\n",
      "logger: TrainLogger\n",
      "device_desc: GeForce GTX 660M 2GB\n",
      "train_data: None\n",
      "val_data: None\n",
      "optimizer: None\n",
      "scheduler: None\n",
      "test_data: VideoDepthFocusDataMp4(type=test, path=../../../datasets/s7_real_mp4)\n",
      "loss_mask: <function TrainSetupDDFF.__init__.<locals>.<lambda> at 0x7fd81c48dd90>\n",
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 10000000\n",
      "sample_size: 4\n",
      "dropout: 0.0\n",
      "ddff_scoring: ccx_last\n",
      "optim_type: adam\n",
      "sgd_mom: 0.9\n",
      "weigth_decay: 0\n",
      "max_gradient: None\n",
      "checkpoint_freq: 5\n",
      "log_img_freq: 1\n",
      "log_val_freq: 5\n",
      "load_pretrained: True\n",
      "save_imgs: False\n",
      "vis_whole_seq: False\n",
      "test_crop: False\n",
      "use_tensorboard: False\n",
      "num_data_threads: 4\n",
      "select_focus_dists: [0.1, 0.1875, 0.3625, 0.45]\n",
      "extend_data_module: None\n",
      "extend_encoding: False\n",
      "dataset: s7_real_mp4\n",
      "sample_skip: 0\n",
      "use_allinfocus: False\n",
      "color_noise_stddev: None\n",
      "depth_noise_stddev: None\n",
      "data_expand: None\n",
      "depth_output_indices: [3]\n",
      "include_coc: False\n",
      "include_fgbg: False\n",
      "test_target_frame: None\n",
      "limit_data: None\n",
      "test_single_img_seq: None\n",
      "five_crop_dataset: False\n",
      "target_indices: None\n",
      "include_flow: False\n",
      "ramp_sample_count: 1\n",
      "fixed_ramp_idx: None\n",
      "fixed_frame_indices: None\n",
      "relative_fixed_frame_indices: False\n",
      "select_rel_indices: None\n",
      "include_all_coc: False\n",
      "pad_to_multiple: 32\n",
      "pad_center: True\n",
      "model_gen: <function <lambda>.<locals>.<lambda> at 0x7fd81c501ea0>\n",
      "model_modifier_dict: None\n",
      "aernn_resize_mode: None\n",
      ")\n",
      "Vis idx 3\n",
      "16:54:30 START TEST\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 24 67 90] [0.1        0.18788439 0.36224484 0.4487434 ]\n",
      "[ 0 21 65 87] [0.1        0.18499847 0.3594798  0.4487434 ]\n",
      "[ 0 16 61 82] [0.1        0.18571141 0.36505324 0.4487434 ]\n",
      "[ 0 24 68 89] [0.1        0.18936221 0.36505324 0.4487434 ]\n",
      "<class 'numpy.ndarray'> [640, 480]\n",
      "Identity\n",
      "<class 'numpy.ndarray'> [640, 480]\n",
      "Identity\n",
      "<class 'numpy.ndarray'> [640, 480]\n",
      "Identity\n",
      "[ 0 17 62 83] [0.1        0.18571141 0.36505324 0.4487434 ]\n",
      "<class 'numpy.ndarray'> [640, 480]\n",
      "Identity\n",
      "[ 0 16 60 82] [0.1        0.18571141 0.36224484 0.4487434 ]\n",
      "[ 0 17 61 83] [0.1        0.18571141 0.36224484 0.4487434 ]\n",
      "[ 0 17 61 83] [0.1        0.18643    0.36224484 0.4487434 ]\n",
      "<class 'numpy.ndarray'> [640, 480]\n",
      "Identity\n",
      "<class 'numpy.ndarray'> [640, 480]\n",
      "Identity\n",
      "<class 'numpy.ndarray'> [640, 480]\n",
      "Identity\n",
      "[ 0 17 61 84] [0.1        0.18571141 0.36224484 0.4487434 ]\n",
      "<class 'numpy.ndarray'> [640, 480]\n",
      "Identity\n",
      "<class 'numpy.ndarray'> [640, 480]\n",
      "Identity\n",
      "[ 0 17 61 82] [0.1        0.18643    0.36505324 0.4487434 ]\n",
      "[ 0 21 65 86] [0.1        0.18499847 0.36224484 0.4487434 ]\n",
      "16:54:34 [Test     1] train_loss: nan mse: nan acc: nan%\n",
      "16:54:34 [Test     2] train_loss: nan mse: nan acc: nan%\n",
      "[ 0 17 61 83] [0.1        0.18571141 0.36224484 0.4487434 ]\n",
      "16:54:34 [Test     3] train_loss: nan mse: nan acc: nan%\n",
      "16:54:35 [Test     4] train_loss: nan mse: nan acc: nan%\n",
      "[ 0 17 61 83] [0.1        0.18499847 0.36224484 0.4487434 ]\n",
      "16:54:35 [Test     5] train_loss: nan mse: nan acc: nan%\n",
      "16:54:35 [Test     6] train_loss: nan mse: nan acc: nan%\n",
      "<class 'numpy.ndarray'> [640, 480]\n",
      "Identity\n",
      "16:54:35 [Test     7] train_loss: nan mse: nan acc: nan%\n",
      "16:54:35 [Test     8] train_loss: nan mse: nan acc: nan%\n",
      "[ 0 23 67 89] [0.1        0.18571141 0.36505324 0.4487434 ]\n",
      "<class 'numpy.ndarray'> [640, 480]\n",
      "<class 'numpy.ndarray'> [640, 480]\n",
      "Identity\n",
      "Identity\n",
      "16:54:35 [Test     9] train_loss: nan mse: nan acc: nan%\n",
      "16:54:35 [Test    10] train_loss: nan mse: nan acc: nan%\n",
      "[ 0 25 67 90] [0.1        0.19086401 0.3594798  0.4487434 ]\n",
      "[ 0 19 64 85] [0.1        0.18788439 0.36505324 0.4487434 ]\n",
      "<class 'numpy.ndarray'> [640, 480]\n",
      "Identity\n",
      "[ 0 22 66 88] [0.1        0.18571141 0.36224484 0.4487434 ]\n",
      "16:54:36 [Test    11] train_loss: nan mse: nan acc: nan%\n",
      "16:54:36 [Test    12] train_loss: nan mse: nan acc: nan%\n",
      "16:54:36 [Test    13] train_loss: nan mse: nan acc: nan%\n",
      "<class 'numpy.ndarray'> [640, 480]\n",
      "Identity\n",
      "[ 0 21 65 86] [0.1        0.19011007 0.36224484 0.4487434 ]\n",
      "<class 'numpy.ndarray'> [640, 480]\n",
      "Identity\n",
      "[ 0 22 66 89] [0.1        0.18571141 0.36224484 0.4530814 ]\n",
      "<class 'numpy.ndarray'> [640, 480]\n",
      "Identity\n",
      "<class 'numpy.ndarray'> [640, 480]\n",
      "Identity\n",
      "16:54:36 [Test    14] train_loss: nan mse: nan acc: nan%\n",
      "16:54:37 [Test    15] train_loss: nan mse: nan acc: nan%\n",
      "<class 'numpy.ndarray'> [640, 480]\n",
      "Identity\n",
      "16:54:37 [Test    16] train_loss: nan mse: nan acc: nan%\n",
      "16:54:37 [Test    17] train_loss: nan mse: nan acc: nan%\n",
      "<class 'numpy.ndarray'> [640, 480]\n",
      "Identity\n",
      "16:54:37 [Test    18] train_loss: nan mse: nan acc: nan%\n",
      "16:54:37 [Test    19] train_loss: nan mse: nan acc: nan%\n",
      "16:54:37 FINISH TEST\n",
      "Saving all test images: ../../../logs/test/03_test_20190730-165437/img\n",
      "Out labels ['depth']\n",
      "image_ids [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "num out 1\n",
      "{\n",
      "    \"0\": {\n",
      "        \"input\": [\n",
      "            \"Tensor [3, 480, 640]\"\n",
      "        ],\n",
      "        \"target\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ],\n",
      "        \"output\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ]\n",
      "    },\n",
      "    \"1\": {\n",
      "        \"input\": [\n",
      "            \"Tensor [3, 480, 640]\"\n",
      "        ],\n",
      "        \"target\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ],\n",
      "        \"output\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ]\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"input\": [\n",
      "            \"Tensor [3, 480, 640]\"\n",
      "        ],\n",
      "        \"target\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ],\n",
      "        \"output\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ]\n",
      "    },\n",
      "    \"3\": {\n",
      "        \"input\": [\n",
      "            \"Tensor [3, 480, 640]\"\n",
      "        ],\n",
      "        \"target\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ],\n",
      "        \"output\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ]\n",
      "    },\n",
      "    \"4\": {\n",
      "        \"input\": [\n",
      "            \"Tensor [3, 480, 640]\"\n",
      "        ],\n",
      "        \"target\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ],\n",
      "        \"output\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ]\n",
      "    },\n",
      "    \"5\": {\n",
      "        \"input\": [\n",
      "            \"Tensor [3, 480, 640]\"\n",
      "        ],\n",
      "        \"target\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ],\n",
      "        \"output\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ]\n",
      "    },\n",
      "    \"6\": {\n",
      "        \"input\": [\n",
      "            \"Tensor [3, 480, 640]\"\n",
      "        ],\n",
      "        \"target\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ],\n",
      "        \"output\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ]\n",
      "    },\n",
      "    \"7\": {\n",
      "        \"input\": [\n",
      "            \"Tensor [3, 480, 640]\"\n",
      "        ],\n",
      "        \"target\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ],\n",
      "        \"output\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ]\n",
      "    },\n",
      "    \"8\": {\n",
      "        \"input\": [\n",
      "            \"Tensor [3, 480, 640]\"\n",
      "        ],\n",
      "        \"target\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ],\n",
      "        \"output\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ]\n",
      "    },\n",
      "    \"9\": {\n",
      "        \"input\": [\n",
      "            \"Tensor [3, 480, 640]\"\n",
      "        ],\n",
      "        \"target\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ],\n",
      "        \"output\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ]\n",
      "    },\n",
      "    \"10\": {\n",
      "        \"input\": [\n",
      "            \"Tensor [3, 480, 640]\"\n",
      "        ],\n",
      "        \"target\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ],\n",
      "        \"output\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ]\n",
      "    },\n",
      "    \"11\": {\n",
      "        \"input\": [\n",
      "            \"Tensor [3, 480, 640]\"\n",
      "        ],\n",
      "        \"target\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ],\n",
      "        \"output\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ]\n",
      "    },\n",
      "    \"12\": {\n",
      "        \"input\": [\n",
      "            \"Tensor [3, 480, 640]\"\n",
      "        ],\n",
      "        \"target\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ],\n",
      "        \"output\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ]\n",
      "    },\n",
      "    \"13\": {\n",
      "        \"input\": [\n",
      "            \"Tensor [3, 480, 640]\"\n",
      "        ],\n",
      "        \"target\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ],\n",
      "        \"output\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ]\n",
      "    },\n",
      "    \"14\": {\n",
      "        \"input\": [\n",
      "            \"Tensor [3, 480, 640]\"\n",
      "        ],\n",
      "        \"target\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ],\n",
      "        \"output\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ]\n",
      "    },\n",
      "    \"15\": {\n",
      "        \"input\": [\n",
      "            \"Tensor [3, 480, 640]\"\n",
      "        ],\n",
      "        \"target\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ],\n",
      "        \"output\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ]\n",
      "    },\n",
      "    \"16\": {\n",
      "        \"input\": [\n",
      "            \"Tensor [3, 480, 640]\"\n",
      "        ],\n",
      "        \"target\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ],\n",
      "        \"output\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ]\n",
      "    },\n",
      "    \"17\": {\n",
      "        \"input\": [\n",
      "            \"Tensor [3, 480, 640]\"\n",
      "        ],\n",
      "        \"target\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ],\n",
      "        \"output\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ]\n",
      "    },\n",
      "    \"18\": {\n",
      "        \"input\": [\n",
      "            \"Tensor [3, 480, 640]\"\n",
      "        ],\n",
      "        \"target\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ],\n",
      "        \"output\": [\n",
      "            \"Tensor [1, 480, 640]\"\n",
      "        ]\n",
      "    }\n",
      "}\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "from types import SimpleNamespace\n",
    "from scripts.train_model import run_model_operation\n",
    "\n",
    "config = \"03_test\"\n",
    "\n",
    "config_dir = \"/home/kevin/Documents/master-thesis/code/mt-project/scripts/test_cfg/dummy/\"\n",
    "\n",
    "config_path = config_dir + config + \".json\"\n",
    "\n",
    "# config_path = \"/home/kevin/Documents/master-thesis/code/mt-project/scripts/test_cfg/final/08_muc_recurae_coc_big.json\"\n",
    "\n",
    "run_model_operation(SimpleNamespace(\n",
    "    **{\"userfs\": False, \"test\": True, \"test_cfg\": config_path}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
